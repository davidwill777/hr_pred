{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cost: 0.4030808210372925 test accuracy: 0.6929134130477905\n",
      "test cost: 0.1734163910150528 test accuracy: 0.6232876777648926\n",
      "test cost: 0.048711150884628296 test accuracy: 0.6612021923065186\n",
      "test cost: 0.019516998901963234 test accuracy: 0.6332046389579773\n",
      "test cost: 0.011109324172139168 test accuracy: 0.65625\n",
      "test cost: 0.009701880626380444 test accuracy: 0.6607539057731628\n",
      "test cost: 0.009241646155714989 test accuracy: 0.6774193644523621\n",
      "test cost: 0.009623861871659756 test accuracy: 0.6356821656227112\n",
      "test cost: 0.0095414062961936 test accuracy: 0.648101270198822\n",
      "test cost: 0.009723477065563202 test accuracy: 0.6300326585769653\n",
      "test cost: 0.009438990615308285 test accuracy: 0.6586715579032898\n",
      "test cost: 0.009598419070243835 test accuracy: 0.6398104429244995\n",
      "test cost: 0.00969719048589468 test accuracy: 0.626719057559967\n",
      "test cost: 0.009589399211108685 test accuracy: 0.6435366272926331\n",
      "test cost: 0.00962976086884737 test accuracy: 0.63818359375\n",
      "test cost: 0.009640882723033428 test accuracy: 0.6364818215370178\n",
      "test cost: 0.009735124185681343 test accuracy: 0.6211059093475342\n",
      "test cost: 0.009737251326441765 test accuracy: 0.6228349208831787\n",
      "test cost: 0.009818397462368011 test accuracy: 0.6112010478973389\n",
      "test cost: 0.009794717654585838 test accuracy: 0.6116417646408081\n",
      "test cost: 0.009805602952837944 test accuracy: 0.611634373664856\n",
      "test cost: 0.009849915280938148 test accuracy: 0.605684757232666\n",
      "test cost: 0.009838702157139778 test accuracy: 0.607358992099762\n",
      "test cost: 0.009821289218962193 test accuracy: 0.6078342199325562\n",
      "test cost: 0.00983104482293129 test accuracy: 0.6081255078315735\n",
      "test cost: 0.009895090013742447 test accuracy: 0.5977198481559753\n",
      "test cost: 0.009829455055296421 test accuracy: 0.6084686517715454\n",
      "test cost: 0.00983002781867981 test accuracy: 0.6075832843780518\n",
      "test cost: 0.00979989767074585 test accuracy: 0.6114526391029358\n",
      "test cost: 0.009868482127785683 test accuracy: 0.6027880311012268\n",
      "test cost: 0.009837406687438488 test accuracy: 0.6074991822242737\n",
      "test cost: 0.009887464344501495 test accuracy: 0.597312331199646\n",
      "test cost: 0.00985525082796812 test accuracy: 0.6019302010536194\n",
      "test cost: 0.00992363877594471 test accuracy: 0.5932809114456177\n",
      "test cost: 0.009830283932387829 test accuracy: 0.6069459915161133\n",
      "test cost: 0.009843348525464535 test accuracy: 0.6044438481330872\n",
      "test cost: 0.009901206009089947 test accuracy: 0.5961934328079224\n",
      "test cost: 0.009894688613712788 test accuracy: 0.5988553166389465\n",
      "test cost: 0.009854347445070744 test accuracy: 0.6032300591468811\n",
      "test cost: 0.0098860589787364 test accuracy: 0.5976863503456116\n",
      "test cost: 0.0099015599116683 test accuracy: 0.597868025302887\n",
      "test cost: 0.009857709519565105 test accuracy: 0.6043181419372559\n",
      "test cost: 0.009866385720670223 test accuracy: 0.6016704440116882\n",
      "test cost: 0.00989221315830946 test accuracy: 0.5969371795654297\n",
      "test cost: 0.009901183657348156 test accuracy: 0.5967545509338379\n",
      "test cost: 0.009903088212013245 test accuracy: 0.5957509875297546\n",
      "test cost: 0.009903478436172009 test accuracy: 0.594605028629303\n",
      "test cost: 0.009927556850016117 test accuracy: 0.590264081954956\n",
      "test cost: 0.009924696758389473 test accuracy: 0.5931565761566162\n",
      "test cost: 0.009938904084265232 test accuracy: 0.59173983335495\n",
      "test cost: 0.00987390335649252 test accuracy: 0.5995447635650635\n",
      "test cost: 0.00994916446506977 test accuracy: 0.5876561999320984\n",
      "test cost: 0.009897355921566486 test accuracy: 0.5980909466743469\n",
      "test cost: 0.009907234460115433 test accuracy: 0.5951815247535706\n",
      "test cost: 0.0098799467086792 test accuracy: 0.5981225967407227\n",
      "test cost: 0.009915778413414955 test accuracy: 0.5944671630859375\n",
      "test cost: 0.009888635016977787 test accuracy: 0.5991989970207214\n",
      "test cost: 0.009935292415320873 test accuracy: 0.5920724868774414\n",
      "test cost: 0.009876161813735962 test accuracy: 0.5994817018508911\n",
      "test cost: 0.009906505234539509 test accuracy: 0.5939270853996277\n",
      "test cost: 0.0098837586119771 test accuracy: 0.5998146533966064\n",
      "test cost: 0.009909599088132381 test accuracy: 0.5960381031036377\n",
      "test cost: 0.0099128857254982 test accuracy: 0.5935244560241699\n",
      "test cost: 0.00987209565937519 test accuracy: 0.6012696623802185\n",
      "test cost: 0.009933737106621265 test accuracy: 0.5930448770523071\n",
      "test cost: 0.009895951487123966 test accuracy: 0.5983820557594299\n",
      "test cost: 0.009868498891592026 test accuracy: 0.6007184982299805\n",
      "test cost: 0.009896831586956978 test accuracy: 0.5953688025474548\n",
      "test cost: 0.009919164702296257 test accuracy: 0.5940157771110535\n",
      "test cost: 0.009915806353092194 test accuracy: 0.5945632457733154\n",
      "test cost: 0.009899520315229893 test accuracy: 0.5946482419967651\n",
      "test cost: 0.00991000421345234 test accuracy: 0.5928952097892761\n",
      "test cost: 0.009869197383522987 test accuracy: 0.6027053594589233\n",
      "test cost: 0.009910504333674908 test accuracy: 0.5963471531867981\n",
      "test cost: 0.00989904161542654 test accuracy: 0.5959144234657288\n",
      "test cost: 0.009910625405609608 test accuracy: 0.5932411551475525\n",
      "test cost: 0.009919845499098301 test accuracy: 0.5950417518615723\n",
      "test cost: 0.009918280877172947 test accuracy: 0.5943748950958252\n",
      "test cost: 0.009911934845149517 test accuracy: 0.5936514735221863\n",
      "test cost: 0.009887744672596455 test accuracy: 0.5980815887451172\n",
      "test cost: 0.009906155988574028 test accuracy: 0.5954559445381165\n",
      "test cost: 0.009886205196380615 test accuracy: 0.5989535450935364\n",
      "test cost: 0.009923450648784637 test accuracy: 0.5906352996826172\n",
      "test cost: 0.009899315424263477 test accuracy: 0.5962527990341187\n",
      "test cost: 0.00989634171128273 test accuracy: 0.5980962514877319\n",
      "test cost: 0.009932687506079674 test accuracy: 0.5917413234710693\n",
      "test cost: 0.00989533681422472 test accuracy: 0.5973744988441467\n",
      "test cost: 0.009926067665219307 test accuracy: 0.591299831867218\n",
      "test cost: 0.009930076077580452 test accuracy: 0.5937045812606812\n",
      "test cost: 0.0099406149238348 test accuracy: 0.5905551910400391\n",
      "test cost: 0.00987961608916521 test accuracy: 0.5994138717651367\n",
      "test cost: 0.009893321432173252 test accuracy: 0.5954837799072266\n",
      "test cost: 0.009938890114426613 test accuracy: 0.5924236178398132\n",
      "test cost: 0.009913739748299122 test accuracy: 0.5949864983558655\n",
      "test cost: 0.009892567992210388 test accuracy: 0.5971153974533081\n",
      "test cost: 0.009902049787342548 test accuracy: 0.5953327417373657\n",
      "test cost: 0.0099025284871459 test accuracy: 0.5974358916282654\n",
      "test cost: 0.009935477748513222 test accuracy: 0.5915641784667969\n",
      "test cost: 0.009913657791912556 test accuracy: 0.5928682088851929\n",
      "test cost: 0.009937482886016369 test accuracy: 0.5884542465209961\n",
      "test cost: 0.009930106811225414 test accuracy: 0.5923410654067993\n",
      "test cost: 0.009940425865352154 test accuracy: 0.5902760624885559\n",
      "test cost: 0.009907550178468227 test accuracy: 0.5945599675178528\n",
      "test cost: 0.009870943613350391 test accuracy: 0.5998097062110901\n",
      "test cost: 0.009908362291753292 test accuracy: 0.5960210561752319\n",
      "test cost: 0.009922993369400501 test accuracy: 0.593342125415802\n",
      "test cost: 0.009897680953145027 test accuracy: 0.5953699350357056\n",
      "test cost: 0.009906796738505363 test accuracy: 0.594365119934082\n",
      "test cost: 0.009894386865198612 test accuracy: 0.5989820957183838\n",
      "test cost: 0.009902563877403736 test accuracy: 0.5977376103401184\n",
      "test cost: 0.009918478317558765 test accuracy: 0.5923611521720886\n",
      "test cost: 0.009912467561662197 test accuracy: 0.5938621759414673\n",
      "test cost: 0.00993209145963192 test accuracy: 0.5927376747131348\n",
      "test cost: 0.009915745817124844 test accuracy: 0.5951054692268372\n",
      "test cost: 0.009934722445905209 test accuracy: 0.5910708904266357\n",
      "test cost: 0.009898449294269085 test accuracy: 0.5954211950302124\n",
      "test cost: 0.009918002411723137 test accuracy: 0.5930858254432678\n",
      "test cost: 0.009927402250468731 test accuracy: 0.5923308730125427\n",
      "test cost: 0.00992568675428629 test accuracy: 0.5934635400772095\n",
      "test cost: 0.009887432679533958 test accuracy: 0.5981966853141785\n",
      "test cost: 0.009900543838739395 test accuracy: 0.5949409604072571\n",
      "test cost: 0.009909519925713539 test accuracy: 0.5955867767333984\n",
      "test cost: 0.009938903152942657 test accuracy: 0.5915282964706421\n",
      "test cost: 0.009896371513605118 test accuracy: 0.595609724521637\n",
      "test cost: 0.009900884702801704 test accuracy: 0.5951713919639587\n",
      "test cost: 0.009925460442900658 test accuracy: 0.5929827094078064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cost: 0.009931174106895924 test accuracy: 0.5915994048118591\n",
      "test cost: 0.009915836155414581 test accuracy: 0.5913004875183105\n",
      "test cost: 0.00991771835833788 test accuracy: 0.5931364893913269\n",
      "test cost: 0.009906251914799213 test accuracy: 0.5964243412017822\n",
      "test cost: 0.009912550449371338 test accuracy: 0.5947169065475464\n",
      "test cost: 0.009917010553181171 test accuracy: 0.5934059023857117\n",
      "test cost: 0.009925025515258312 test accuracy: 0.5896567702293396\n",
      "test cost: 0.009921845048666 test accuracy: 0.5937944650650024\n",
      "test cost: 0.009914490394294262 test accuracy: 0.595026433467865\n",
      "test cost: 0.009890586137771606 test accuracy: 0.596733808517456\n",
      "test cost: 0.009924525395035744 test accuracy: 0.5900757312774658\n",
      "test cost: 0.009931623935699463 test accuracy: 0.5918654799461365\n",
      "test cost: 0.00993435736745596 test accuracy: 0.5914028882980347\n",
      "test cost: 0.00992012768983841 test accuracy: 0.590467631816864\n",
      "test cost: 0.009914535097777843 test accuracy: 0.5927477478981018\n",
      "test cost: 0.00990213267505169 test accuracy: 0.5963608622550964\n",
      "test cost: 0.009937294758856297 test accuracy: 0.5910003185272217\n",
      "test cost: 0.00990513525903225 test accuracy: 0.5946294665336609\n",
      "test cost: 0.009915394708514214 test accuracy: 0.5918941497802734\n",
      "test cost: 0.009914482943713665 test accuracy: 0.5943583846092224\n",
      "test cost: 0.00992645788937807 test accuracy: 0.5925315618515015\n",
      "test cost: 0.009927364066243172 test accuracy: 0.5906872749328613\n",
      "test cost: 0.009917618706822395 test accuracy: 0.5909964442253113\n",
      "test cost: 0.009935924783349037 test accuracy: 0.5920649170875549\n",
      "test cost: 0.009908256120979786 test accuracy: 0.5956702828407288\n",
      "test cost: 0.009920049458742142 test accuracy: 0.591511607170105\n",
      "test cost: 0.009946647100150585 test accuracy: 0.5893425941467285\n",
      "test cost: 0.009932506829500198 test accuracy: 0.5920560359954834\n",
      "test cost: 0.009934874251484871 test accuracy: 0.590873658657074\n",
      "test cost: 0.00991346500813961 test accuracy: 0.5930502414703369\n",
      "test cost: 0.009907932952046394 test accuracy: 0.5943265557289124\n",
      "test cost: 0.009922539815306664 test accuracy: 0.593076229095459\n",
      "test cost: 0.009932499378919601 test accuracy: 0.5918068289756775\n",
      "test cost: 0.009935340844094753 test accuracy: 0.5892578959465027\n",
      "test cost: 0.009916435927152634 test accuracy: 0.5929716229438782\n",
      "test cost: 0.009919579140841961 test accuracy: 0.594876766204834\n",
      "test cost: 0.009928149171173573 test accuracy: 0.5918644070625305\n",
      "test cost: 0.009890415705740452 test accuracy: 0.596567690372467\n",
      "test cost: 0.009919753298163414 test accuracy: 0.5919286012649536\n",
      "test cost: 0.009913412854075432 test accuracy: 0.5953152179718018\n",
      "test cost: 0.009919820353388786 test accuracy: 0.5946958661079407\n",
      "test cost: 0.009924251586198807 test accuracy: 0.5909665822982788\n",
      "test cost: 0.00990256480872631 test accuracy: 0.5936083793640137\n",
      "test cost: 0.009902885183691978 test accuracy: 0.5969111323356628\n",
      "test cost: 0.009933841414749622 test accuracy: 0.5914459824562073\n",
      "test cost: 0.009906992316246033 test accuracy: 0.5945026874542236\n",
      "test cost: 0.009894918650388718 test accuracy: 0.5964437127113342\n",
      "test cost: 0.009914854541420937 test accuracy: 0.5947619080543518\n",
      "test cost: 0.00994587130844593 test accuracy: 0.5886484384536743\n",
      "test cost: 0.009893964044749737 test accuracy: 0.5956290364265442\n",
      "test cost: 0.009917899034917355 test accuracy: 0.5924217700958252\n",
      "test cost: 0.009928216226398945 test accuracy: 0.5919807553291321\n",
      "test cost: 0.00991782359778881 test accuracy: 0.5944405794143677\n",
      "test cost: 0.009944763965904713 test accuracy: 0.588528037071228\n",
      "test cost: 0.009920193813741207 test accuracy: 0.5920174717903137\n",
      "test cost: 0.009928995743393898 test accuracy: 0.591975212097168\n",
      "test cost: 0.009910316206514835 test accuracy: 0.596265971660614\n",
      "test cost: 0.009938287548720837 test accuracy: 0.5893605351448059\n",
      "test cost: 0.009911555796861649 test accuracy: 0.5929916501045227\n",
      "test cost: 0.009933426044881344 test accuracy: 0.5923651456832886\n",
      "test cost: 0.009927468374371529 test accuracy: 0.592770516872406\n",
      "test cost: 0.009900050237774849 test accuracy: 0.5958341360092163\n",
      "test cost: 0.009907832369208336 test accuracy: 0.5948222875595093\n",
      "test cost: 0.009934675879776478 test accuracy: 0.5913730263710022\n",
      "test cost: 0.009928027167916298 test accuracy: 0.5925268530845642\n",
      "test cost: 0.009931394830346107 test accuracy: 0.5906975865364075\n",
      "test cost: 0.009912490844726562 test accuracy: 0.5930907726287842\n",
      "test cost: 0.009927208535373211 test accuracy: 0.5922850966453552\n",
      "test cost: 0.009905336424708366 test accuracy: 0.5934382677078247\n",
      "test cost: 0.009923427365720272 test accuracy: 0.5910939574241638\n",
      "test cost: 0.009929713793098927 test accuracy: 0.5916262269020081\n",
      "test cost: 0.009924707934260368 test accuracy: 0.5922617316246033\n",
      "test cost: 0.009908489882946014 test accuracy: 0.5932827591896057\n",
      "test cost: 0.009928219951689243 test accuracy: 0.5904982089996338\n",
      "test cost: 0.009927111677825451 test accuracy: 0.5927063226699829\n",
      "test cost: 0.009945851750671864 test accuracy: 0.5886445045471191\n",
      "test cost: 0.009914499707520008 test accuracy: 0.5926710367202759\n",
      "test cost: 0.009921160526573658 test accuracy: 0.5912841558456421\n",
      "test cost: 0.009936943650245667 test accuracy: 0.591103196144104\n",
      "test cost: 0.009921260178089142 test accuracy: 0.5927506685256958\n",
      "test cost: 0.009911716915667057 test accuracy: 0.5914610624313354\n",
      "test cost: 0.009917040355503559 test accuracy: 0.5918745994567871\n",
      "test cost: 0.009936818853020668 test accuracy: 0.5914582014083862\n",
      "test cost: 0.009927654638886452 test accuracy: 0.5923219919204712\n",
      "test cost: 0.009909492917358875 test accuracy: 0.5939042568206787\n",
      "test cost: 0.009926347061991692 test accuracy: 0.5908971428871155\n",
      "test cost: 0.009929543361067772 test accuracy: 0.5916205048561096\n",
      "test cost: 0.009929971769452095 test accuracy: 0.5913453698158264\n",
      "test cost: 0.009904276579618454 test accuracy: 0.5937222838401794\n",
      "test cost: 0.009932084940373898 test accuracy: 0.5891005396842957\n",
      "test cost: 0.009913809597492218 test accuracy: 0.5941113829612732\n",
      "test cost: 0.009918677620589733 test accuracy: 0.5936914086341858\n",
      "test cost: 0.009930213913321495 test accuracy: 0.5898965001106262\n",
      "test cost: 0.009918076917529106 test accuracy: 0.5920079350471497\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "\n",
    "def binary_focal_loss(gamma=5, alpha=0.3):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "    適用於二分類問題的focal loss\n",
    "    \n",
    "    focal_loss(p_t) = -alpha_t * (1 - p_t)**gamma * log(p_t)\n",
    "        where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "    gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "    \n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true shape need be (None,1)\n",
    "        y_pred need be compute after sigmoid\n",
    "        \"\"\"\n",
    "        \n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        \n",
    "        alpha_t = y_true*alpha + (K.ones_like(y_true)-y_true)*(1-alpha)\n",
    "    \n",
    "        p_t = y_true*y_pred + (K.ones_like(y_true)-y_true)*(K.ones_like(y_true)-y_pred) + K.epsilon()\n",
    "        focal_loss = - alpha_t * K.pow((K.ones_like(y_true)-p_t),gamma) * K.log(p_t)\n",
    "        \n",
    "        return K.mean(focal_loss)\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "get_custom_objects().update({'focal_loss':binary_focal_loss()})\n",
    "\n",
    "\n",
    "#st = RandomOverSampler(random_state=1)\n",
    "sc = StandardScaler()\n",
    "    \n",
    "df = pd.read_csv('./all_pre_model_2.csv',header=0)\n",
    "\n",
    "df = df.drop(['離職日','外語專長種類數','第二個月忘刷卡次數','第三個月病假時數','體育專長種類數'\n",
    "              ,'個人專長種類數','第三個月曠職時數','第二個月遺失卡次數'\n",
    "            ,'第三個月未帶卡次數','第三個月遺失卡次數','第二個月遲到次數','第二個月未帶卡次數'\n",
    "            ,'第三個月遲到次數'],axis=1)\n",
    "\n",
    "cols = ['年資','是否離職','年齡','姓別代號','台成清交(最高)','理工科系(最高)','台成清交(次高)',\n",
    "        '理工科系(次高)','婚姻代號','撫養人數','第三個月事假時數',\n",
    "        '第三個月特休時數','第三個月忘刷卡次數','第二個月事假時數','第二個月病假時數','第二個月曠職時數',\n",
    "        '第二個月特休時數','近一年考績']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x = df.drop(['是否離職'],axis = 1).values\n",
    "#y = df['是否離職'].values\n",
    "\n",
    "\n",
    "\n",
    "df2 = []\n",
    "cv_accuracies = []\n",
    "steps = []\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "#windows = 50000\n",
    "#steps = 1000\n",
    "#data = np.arange(len(df))\n",
    "#print(data)\n",
    "\n",
    "'''\n",
    "def rolling(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "a = rolling(data,windows)\n",
    "print(a.shape)\n",
    "'''\n",
    "#scores_roc = []\n",
    "#scores_accuracy = []\n",
    "m = 0\n",
    "\n",
    "df['進企業日'] = (df['進企業日'] + 19110000)\n",
    "temp = []\n",
    "count = 0\n",
    "day = df['進企業日']\n",
    "\n",
    "for i in range(0,len(day)):\n",
    "    aaa = str(day.iloc[i])\n",
    "    string = aaa\n",
    "    temp.append(string[4:6])\n",
    "    print(temp)  \n",
    "\n",
    "#print(len(temp))\n",
    "for j in range(0,len(temp)-1,1):\n",
    "    \n",
    "    if (temp[j] == temp[j+1]):\n",
    "        count = count + 1\n",
    "    else:\n",
    "        steps.append(count)\n",
    "        count = 0\n",
    "        #print(steps)\n",
    "        #break\n",
    "print(steps)\n",
    "\n",
    "\n",
    "clf = Sequential()\n",
    "clf.add(Dense(48, input_dim=17,kernel_regularizer=regularizers.l1_l2(l1=0.002,l2=0.002)))\n",
    "clf.add(Activation('relu'))\n",
    "clf.add(Dropout(0.3))\n",
    "clf.add(Dense(24,kernel_regularizer=regularizers.l1_l2(l1=0.002,l2=0.002)))\n",
    "clf.add(Activation('relu'))\n",
    "clf.add(Dropout(0.3))\n",
    "clf.add(Dense(1))\n",
    "clf.add(Activation('sigmoid'))\n",
    "clf.compile(optimizer='adam',loss=['focal_loss'],metrics=['accuracy'])\n",
    "\n",
    " \n",
    "\n",
    "step = 0    \n",
    "q = steps[0]\n",
    "p = -1\n",
    "z = 0\n",
    "w = 7\n",
    "sum_p = []\n",
    "sum_ten = 0\n",
    "temp1 = []\n",
    "year = 5\n",
    "\n",
    "for v in range(0,year,1):\n",
    "    temp1.append(steps[v])\n",
    "    sum_ten = sum(temp1)\n",
    "#print(sum_ten)\n",
    "\n",
    "for x in range(0,1,1): #10 years\n",
    "    #print(steps[x])\n",
    "    for o in range(p+1,sum_ten+1,1):\n",
    "       #print((p+1,q+1))\n",
    "       df2.append(df.iloc[o,:])\n",
    "       #print(p+o)\n",
    "       m = m + 1\n",
    "    \n",
    "       if m == (sum_ten - p):\n",
    "            #print(1111)     \n",
    "        \n",
    "            test_1=pd.DataFrame(columns=cols,data=df2)\n",
    "            #print(test_1.shape)\n",
    "            \n",
    "            x = test_1.drop(['是否離職'],axis = 1).values\n",
    "            \n",
    "            y = test_1['是否離職'].values\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "            '''\n",
    "            x = test_1[cols]\n",
    "            x = x.drop(['是否離職'],axis=1)\n",
    "            x_train_pos_data = x.iloc[:int(len(x) * 0.7)].copy()   \n",
    "            x_train_pos_data = x_train_pos_data.values\n",
    "            x_test_pos_data = x.iloc[int(len(x) * 0.7):].copy()\n",
    "            x_test_pos_data = x_test_pos_data.values\n",
    "            \n",
    "            \n",
    "            y = test_1['是否離職']\n",
    "            y_train_pos_data = y.iloc[:int(len(y) * 0.7)].copy()    \n",
    "            y_train_pos_data = y_train_pos_data.values\n",
    "            y_test_pos_data = y.iloc[int(len(x) * 0.7):].copy()  \n",
    "            y_test_pos_data = y_test_pos_data.values\n",
    "            '''\n",
    "            #train_resample,train_resample_target = st.fit_sample(X_train,y_train)\n",
    "           \n",
    "            X_train = sc.fit_transform(X_train)\n",
    "            X_test = sc.fit_transform(X_test)\n",
    "\n",
    "            \n",
    "            #clf.summary()\n",
    "            #clf.compile(optimizer='adam',loss=[binary_focal_loss(alpha=.25, gamma=2)],metrics=['accuracy'])\n",
    "            history = clf.fit(X_train, y_train, epochs = 10,verbose=0)            \n",
    "            cost, accuracy = clf.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "            #y_pred = clf.predict_classes(X_test)\n",
    "            cv_accuracies.append(accuracy)\n",
    "            print('test cost:', cost, 'test accuracy:', accuracy)\n",
    "            m = 0 \n",
    "\n",
    "\n",
    "q = sum_ten + steps[year]\n",
    "\n",
    "for x in range(year,len(steps)+1,1): #every 1 year\n",
    "    #print(steps[x])\n",
    "    for o in range(sum_ten+1,q+1,1):\n",
    "       #print((p+1,q+1))\n",
    "       df2.append(df.iloc[o,:])\n",
    "       #print(p+o)\n",
    "       m = m + 1\n",
    "    \n",
    "       if m == (q - sum_ten):\n",
    "            #print(1111)     \n",
    "        \n",
    "            test_1=pd.DataFrame(columns=cols,data=df2)\n",
    "            #print(test_1.shape)\n",
    "            \n",
    "            x = test_1.drop(['是否離職'],axis = 1).values\n",
    "            \n",
    "            y = test_1['是否離職'].values\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "            '''\n",
    "            x = test_1[cols]\n",
    "            x = x.drop(['是否離職'],axis=1)\n",
    "            x_train_pos_data = x.iloc[:int(len(x) * 0.7)].copy()   \n",
    "            x_train_pos_data = x_train_pos_data.values\n",
    "            x_test_pos_data = x.iloc[int(len(x) * 0.7):].copy()\n",
    "            x_test_pos_data = x_test_pos_data.values\n",
    "            \n",
    "            \n",
    "            y = test_1['是否離職']\n",
    "            y_train_pos_data = y.iloc[:int(len(y) * 0.7)].copy()    \n",
    "            y_train_pos_data = y_train_pos_data.values\n",
    "            y_test_pos_data = y.iloc[int(len(x) * 0.7):].copy()  \n",
    "            y_test_pos_data = y_test_pos_data.values\n",
    "            '''\n",
    "            #train_resample,train_resample_target = st.fit_sample(X_train,y_train)\n",
    "           \n",
    "            X_train = sc.fit_transform(X_train)\n",
    "            X_test = sc.fit_transform(X_test)\n",
    "\n",
    "            \n",
    "            #clf.summary()\n",
    "            #clf.compile(optimizer='adam',loss=[binary_focal_loss(alpha=.25, gamma=2)],metrics=['accuracy'])\n",
    "            history = clf.fit(X_train, y_train, epochs = 10,verbose=0)           \n",
    "            cost, accuracy = clf.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "            #y_pred = clf.predict_classes(X_test)\n",
    "            cv_accuracies.append(accuracy)\n",
    "            print('test cost:', cost, 'test accuracy:', accuracy)\n",
    "            #step = steps\n",
    "            #print(step)\n",
    "            m = 0 \n",
    "            #if p == -1:\n",
    "                \n",
    "                #p = p + steps[z] + 1\n",
    "            #else:\n",
    "            #sum_ten = sum_ten + steps[z]\n",
    "            \n",
    "            if w != 18:\n",
    "                for z in range(0,w,1):\n",
    "                    sum_p.append(steps[z])\n",
    "                    #print(sum_p)\n",
    "                    q = sum(sum_p)\n",
    "                                    \n",
    "            sum_p = []\n",
    "            #print(q)\n",
    "            \n",
    "            if w != 18:\n",
    "                w = w + 1\n",
    "                \n",
    "            #print(w)\n",
    "                #z = z + 1\n",
    "            \n",
    "            #for k in range(steps+step+1,len(temp)-1,1):\n",
    "        \n",
    "             #   if (temp[k] == temp[k+1]):\n",
    "            \n",
    "              #      count = count + 1\n",
    "            \n",
    "               # else:\n",
    "                 #   step = steps + step  \n",
    "                #    steps = count\n",
    "                 #   count = 0\n",
    "                    #print(steps,step)            \n",
    "                 #   continue \n",
    "          \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    55924\n",
       "1    37785\n",
       "Name: 是否離職, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['是否離職'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "plt.title('MLP_NN with Focal_loss Rolling model')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(cv_accuracies)\n",
    "plt.savefig('NNct')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
